---
---

## Read in data

We'll be using the data modified from the [palmerpenguins](https://allisonhorst.github.io/palmerpenguins/index.html) package, which provides a dataset about 3 different species of penguins collected at [Palmer Station Antarctica LTER](https://pal.lternet.edu/). 

![]({% include asset.html path="images/lter_penguins.png" %}){: width="50%"}  
*Credit: [Artwork by @allison_horst](https://www.allisonhorst.com/)*
{:.captioned}


===

For this lesson, the data has been split up into separate files -- one for each study date when nests were observed. The sampling date is included in the file name but not in the data itself. 

Our goal is to read in all 50 files from the **penguins** folder into one data frame, and include the sampling date from each file name in the data. We will do this using `map` functions in the `purrr` package. The inputs we will need are (1) a list of objects to iterate over, and (2) the function to apply to each one. Before seeing `map` in action, we will explore the inputs. 

===

The list of objects to iterate over is a vector file names in the **penguins** folder, which can be created using `dir_ls` in the `fs` package. `fs` contains functions to work with files, filepaths, and directories. Most functions are named based on their [unix equivalent](https://fs.r-lib.org/articles/function-comparisons.html), with the corresponding prefix `file_`, `path_`, or `dir_`. 


```{r, handout = 0}
library(fs)
penguin_files <- dir_ls('data/penguins')
```

===

If we were interested in only a subset of files in that directory, we could filter them by supplying a pattern to the argument `glob` or `regexp`, such as "only files with the word `penguin` in the name ending in `.csv`". 

```{r, eval=FALSE}
dir_ls('data/penguins', glob = "*penguins*.csv")
```

===

Check out some specialized functions can extract or retrieve parts of path.  

any other arguments?

```{r}
penguin_files[1] %>% path_dir()
penguin_files[1] %>% path_ext_remove()
penguin_files[1] %>% path_ext()
```



===

The function we want to apply to each of the file names is read_csv in the `readr` package. 


By default, the data type for each column is determined by [parsing](https://readr.tidyverse.org/articles/readr.html#vector-parsers) the first 1,000 rows of the table. The `col_types` argument in `read_csv` offers more control, which can help ensure consistency across files. One way to specify column types is a character vector using these codes:

| character   | data type       |
|-------------+------------------|
| `c`    |  character/string    |
| `i`    |  integer             |
| `n`    |  numeric             |
| `d`    |  double              |
| `l`    | logical              |
| `f`    | factor/categorical   |
| `D`    | date             |
| `T`    | date time        |
| `t`    | time       |
| `?`    | guess      |
| `_` or `-` | skip this column |

```{r, handout = 0}
pg_df1 <- read_csv(penguin_files[1], col_types = "cdcccccddddcddccc")
```

===

Or use `spec_csv` to generate a column specification from the first file that can be passed to the col_types argument. 

```{r, handout = 0, message=FALSE}
my_col_types <- spec_csv(penguin_files[1])
pg_df <- map_df(penguin_files, ~read_csv(.x, col_types = my_col_types))
```

===

## Map functions

The approach to iteration in the tidyverse is by using `map` functions in the `purrr` package. 

Compared to the apply functions, map functions offer **predictable return objects** and **consistent syntax**. 

The arguments to map are: 

* `.x` - a list of things to iterate over
* `.f` - what to do for each item in `.x`

`.f` can be either the name of an existing function, or an unnamed "anonymous" function created from a formula. 

===

Read all `penguin_files` into a list using:

```
map(.x = penguin_files, .f = read_csv)
```

Or use `~` to specify the function and arguments:

```
 map(.x = penguin_files, ~read_csv(.x))
```

===

Whereas `map` always returns a list, there are `map_*` functions for returning specific types of vectors (e.g. `map_chr` or `map_int`). Use `map_dfr` for returning *one* dataframe:

```{r, message=FALSE, handout = 0}
pg_df <- map_dfr(penguin_files, ~read_csv(.x))
```



===

Another handy argument for `map_dfr` is `.id` for putting the names of each item of `.x` into a column. 

```{r, handout = 0, message=FALSE, results='hide'}
pg_df <- map_dfr(penguin_files, ~read_csv(.x), .id = "filename")
```

===

## Combine operations with pipes


![pipe]({% include asset.html path="images/pipe.jpeg" %}){: width="50%"}

Remember the `%>%` ? 

Readability is one of the core tenets of the tidyverse and this is accomplished with piped workflows. The functions are designed to work together based on the first argument and the type of output returned. 
{:.notes}

===

Let's combine our previous steps together without creating intermediate objects:

```{r, message = FALSE, handout = 0}
pg_df <- dir_ls("data/penguins") %>%
  map_dfr(~read_csv(.x), .id = "filename")
```

This code creates a vector of file names with `dir_ls()`, and then "maps" the `read_csv()` function over each file. The output of each `read_csv()` function is combined together into one dataframe called `pg_df`, along with an additional column with the file name each row of data came from. 

===

